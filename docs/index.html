<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="Stylesheet" href="index.css">
    <link href="https://fonts.googleapis.com/css2?family=Raleway:wght@500&display=swap" rel="stylesheet">
</head>

<body>
    <div class="head">
        <div class="head-in">
            <div class="head-title">Hashtag Network Analysis</div>
            <div class="head-sub">Saurabh Burewar | Rituraj Kulshresth</div>
        </div>
    </div>
    <div id="page">
        <div id="page_nav" class="hide">
            <div class="page_nav_in">
                <div class="page_nav_but navselected" id="op1">Twitter</div>
                <div class="page_nav_but" id="op2">Koo</div>
                <!-- <div class="page_nav_but" id="op3">Analysis</div> -->
                <div class="page_nav_gap"></div>
                <div class="page_nav_contri">
                    <div class="page_nav_contri_box">Contributors</div>
                    <div class="page_nav_contri_box">
                        <a href="https://github.com/saurabhburewar"><img src="./images/saurabh.jpg" alt=""> Saurabh Burewar</a>
                    </div>
                    <div class="page_nav_contri_box">
                        <a href="https://github.com/RiturajKulshresth"><img src="./images/rituraj.jfif" alt=""> Rituraj Kulshresth</a>
                    </div>
                </div>
                <div class="page_nav_copy">
                    <svg id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 291.7 291.7"><defs><style>.cls-1{fill:#838383;}</style></defs><title>cp</title><path class="cls-1" d="M150.27,4.8C230.75,4.8,296.08,70.22,296,150.73A145.86,145.86,0,0,1,150.1,296.5C69.21,296.45,4.25,231.1,4.3,149.83,4.35,69.93,69.91,4.8,150.27,4.8Zm-.09,27.81a118.1,118.1,0,0,0-118.06,118C32,215.63,84.94,268.63,150,268.68s118.1-52.82,118.15-117.88A118.11,118.11,0,0,0,150.17,32.61Z" transform="translate(-4.3 -4.8)"/><path class="cls-1" d="M193.19,194.06l19.5,19.5c-28.62,30.31-83,37.17-121.1,4-39-34-40.6-94.62-3.39-130.66C125,51.26,181.48,55.31,213.05,88l-19.69,19.32c-14.64-13.89-32-19.87-52-17.12-15.58,2.14-28.39,9.59-38.42,21.69a60.9,60.9,0,0,0,3,80.79,59.2,59.2,0,0,0,43.44,19C166.39,211.93,181,205.77,193.19,194.06Z" transform="translate(-4.3 -4.8)"/></svg>
                    All Rights Reserved
                </div>
            </div>
        </div>
        <div class="page_in">
            <div id="page_view1">
                <div class="page_heading">Data Collection and Preprocessing</div>
                We chose to collect the data regarding the tweets and the user who first wrote them. <br><br>
                We used a Standard package developer account for access to tweets. This only gives the tweet data for the last two weeks. To get the data of the tweets we used Tweepy which is a python library to access the Twitter API with ease. We used Tweepy to get the data of the tweets such as username, description, location, following, followers, total tweets, retweet count, text, has text, t_id. This data was used to understand the information format provided by Twitter. Following this, we selected the tweets belonging to a particular hashtag and collected 1000 to 2500 tweets. However, Twitter treats retweets as single tweets while responding to a request through the API hence all the tweets that were collected had to be checked if they are retweets or not and if they are already recorded. If the tweet id that we get is new it is stored for further processing. Twitter has a limit of 900 tweet id requests per 15 min which makes the process considerably slow and tedious. Twitter also has a rate limit of 75 access requests for the tweet details hence we did not collect the details initially. Once the individual non-repetitive tweets were collected we then ran another program to get the tweet details and check for the retweets. the process was broken into two parts since the limit of 75 accesses per 15 min would make the collection of tweet ids very slow. Hence we only collected the ids which have a higher access rate limit. also, the rate limit for checking the details based on the tweet id and collecting the retweeter info was the same 75 tweets access per 15 min so it made sense to club these processes together into one and complete the data collection. 
                <br><br>
                Next, we create a master file with data of the tweet and the individual who posted the tweet originally by exporting the pandas data frame storing the data. The data collected are username, following, followers, total tweets, retweet count, retweeter list. The retweeter list is used to create a network using networkx and exported as an edgelist. This process is extremely slow since the data access rate provided by Twitter API is 75 requests per 15 minutes therefore it takes hours to collect the data of a tweet at a time. Also, multiple exceptions need to be handled since the connection between Tweepy and the API breaks after a minute of inactivity, hence we need to reconnect it again and again. Since the API request rate is so slow for Twitter we chose not to make the hashtag-hashtag network. 
                <br><br>
                <b>NOTE:</b> The data collected from the twitter API was taken from the week starting from 26/10/2021 to 1/11/2021 for all the hashtags.
                <br><br>
                <div class="page_heading">Networks</div>
                To analyse the data we extracted from twitter, we built a retweet network from them.
                <br><br>
                <ul>
                    <li><i>Retweet network:</i> Every node is a user and an edge is formed when a user retweets/rekoo-es another user.</li>
                </ul>
                <br>
                Getting hashtags would significantly increase the time to get the data due to API limitations, which limited us to retweet network only.
                <br><br>
                Below are the images of all the twitter networks built in this project.
                <br><br>
                <img src="images/networks/twitter/1000 blm.png" alt="Network image">
                <div class="page_caption">#BlackLivesMatter</div>
                <img src="images/networks/twitter/blacklivesmatter_update_1000.png" alt="Network image">
                <div class="page_caption">#BlackLivesMatter_update</div>
                <img src="images/networks/twitter/diwali_1000.png" alt="Network image">
                <div class="page_caption">#Diwali</div>
                <img src="images/networks/twitter/lgbtq_1000.png" alt="Network image">
                <div class="page_caption">#LGBTQ</div>
                <img src="images/networks/twitter/ufo_1000.png" alt="Network image">
                <div class="page_caption">#ufo</div>
                <img src="images/networks/twitter/whitelivesmatter_1000.png" alt="Network image">
                <div class="page_caption">#whitelivesmatter</div>
                <img src="images/networks/twitter/bob_2500.png" alt="Network image">
                <div class="page_caption">#BoycottBollywood</div>
                <img src="images/networks/twitter/t20_2500.png" alt="Network image">
                <div class="page_caption">#T20WorldCup</div>
                <img src="images/networks/twitter/metoo.png" alt="Network image">
                <div class="page_caption">#metoo</div>
                <img src="images/networks/twitter/crackerban_2500.png" alt="Network image">
                <div class="page_caption">#crackerban</div>
                <img src="images/networks/twitter/viratkohli_2500.png" alt="Network image">
                <div class="page_caption">#viratkholi</div>
                <img src="images/networks/twitter/autism.png" alt="Network image">
                <div class="page_caption">#autism</div>
                <img src="images/networks/twitter/flatearth.png" alt="Network image">
                <div class="page_caption">#FlatEarth</div>
                <img src="images/networks/twitter/spectrum.png" alt="Network image">
                <div class="page_caption">#StopSpectrum10K</div>
                <br><br>
                Further analysis and observations can be read in the report <a href="https://github.com/saurabhburewar/Data-and-Networks_Hashtag-analysis/blob/main/Report/Hashtag%20Network%20Analysis%20report.pdf">here.</a>
                <br><br>
            </div>
            <div id="page_view2">
                <div class="page_heading">Data Collection and Preprocessing</div>
                Koo is a fairly new social media platform and hence doesn't have public APIs that can be accessed to get easy access to data. So, we scraped the Koo website feed to get the data. 
                <br><br>
                The Koo web app feed can be seen in two ways - A hashtag-specific feed where all posts are pertaining to a hashtag or a combined feed with all posts. We chose to scrape the hashtag-specific feed to get data targeted to a specific tag. The feed page itself has a simple layout with infinite scrolling which loads more posts as we scroll. Each post has post and user information like username, post content, hashtags, etc., and also has a "rekoo" option (similar to retweet) at the bottom which on clicking also shows the users who have "re-kooed" the post.
                <br><br>
                The HTML of the feed page is simple with a container div containing all the posts. Each post is a div tag with a unique id which further contains all information about the post. Our program scrapes important information from each post like username, content, likes, hashtags, etc. using ids and class names of the corresponding div tags and if the post has been rekooed, it scrapes the usernames of rekooers as well. This is done by executing a click on the rekoo option which opens a modal and then reading the usernames of all users that appear in the list in the modal. The program also executes scrolling to load more posts. The program also saves the ids of the posts that have been scraped to avoid duplicate posts in the feed. It also executes scrolling to load more posts once the existing ones are scrapped.
                <br><br>
                We used the Selenium library for web-scraping since it makes scrolling and opening and closing of the rekoo list possible using JavaScript executions.
                <br><br>
                <b>NOTE:</b> The data corresponds to 23/10/2021 to 06/11/2021 for <i>#t20worldcup</i> and all the available posts for other hashtags (since the activity is not as high).
                <br><br>
                <div class="page_heading">Networks</div>
                To analyse the data we extracted from Koo webapp, we built two types of networks from them. 
                <br><br>
                <ul>
                    <li><i>Retweet network:</i> Every node is a user and an edge is formed when a user retweets/rekoo-es another user.</li>
                    <li><i>Hashtag-Hashtag network:</i> Every node is a hashtag and when two hashtags appear in the same tweet/koo, there is an edge between them.</li>
                </ul>
                <br><br>
                Below are the images of the retweet networks built for Koo in this project.
                <br><br>
                <img src="images/networks/koo/covid_graph.png" alt="Network image">
                <div class="page_caption">#covid19</div>
                <img src="images/networks/koo/pollution_graph.png" alt="Network image">
                <div class="page_caption">#pollution</div>
                <img src="images/networks/koo/t20_graph.png" alt="Network image">
                <div class="page_caption">#t20worldcup</div>
                <img src="images/networks/koo/vaccine_graph.png" alt="Network image">
                <div class="page_caption">#VaccineCentury</div>
                <br><br>
                Below are the images of the hashtag-hashtag networks built for Koo in this project.
                <br><br>
                <img src="images/networks/koo/covid_hash.png" alt="Network image">
                <div class="page_caption">#covid19</div>
                <img src="images/networks/koo/pollution_hash.png" alt="Network image">
                <div class="page_caption">#pollution</div>
                <img src="images/networks/koo/t20_hash.png" alt="Network image">
                <div class="page_caption">#t20worldcup</div>
                <img src="images/networks/koo/vaccine_hash.png" alt="Network image">
                <div class="page_caption">#VaccineCentury</div>
                <br><br>
                Further analysis and observations can be read in the report <a href="https://github.com/saurabhburewar/Data-and-Networks_Hashtag-analysis/blob/main/Report/Hashtag%20Network%20Analysis%20report.pdf">here.</a>
                <br><br>
            </div>
            <!-- <div id="page_view3">
                Analysis
            </div> -->
        </div>
    </div>
    <script src="./index.js"></script>
</body>

</html>